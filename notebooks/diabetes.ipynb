{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb090f3",
   "metadata": {},
   "source": [
    "# Diabetes Risk Prediction (with Explainable AI)\n",
    "\n",
    "This notebook walks you step-by-step through:\n",
    "1. Loading the PIMA Indians Diabetes dataset\n",
    "2. Cleaning & imputing impossible zeros\n",
    "3. Feature engineering (BMI category, Glucose/BMI ratio)\n",
    "4. Train/test split with stratification\n",
    "5. Pipelines with SMOTE and models (LR, RF, XGB)\n",
    "6. Cross-validation\n",
    "7. Explainability with SHAP\n",
    "8. Saving and using the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b598ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "sns.set(context=\"notebook\", style=\"whitegrid\")\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31fe4a",
   "metadata": {},
   "source": [
    "## Load data & sanity checks\n",
    "Place your CSV at `../data/diabetes.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf70540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/diabetes.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "df.info()\n",
    "print(\"\\nOutcome value counts:\\n\", df[\"Outcome\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e1c517",
   "metadata": {},
   "source": [
    "## Treat impossible zeros as missing (NaN)\n",
    "We will replace zeros in specific columns with NaN so we can impute them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f21259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "zero_invalid_cols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "for c in zero_invalid_cols:\n",
    "    df[c] = df[c].replace(0, np.nan)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea771380",
   "metadata": {},
   "source": [
    "## Quick EDA\n",
    "We plot class balance, histograms, and a correlation heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512aaa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"Outcome\", data=df)\n",
    "plt.title(\"Outcome (0=No, 1=Yes)\")\n",
    "plt.show()\n",
    "\n",
    "df.hist(figsize=(12,8))\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=False, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58e531b",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "- BMI Category using WHO cutoffs\n",
    "- Glucose/BMI ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d068de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmi_category(bmi):\n",
    "    if pd.isna(bmi):\n",
    "        return np.nan\n",
    "    if bmi < 18.5:\n",
    "        return \"Underweight\"\n",
    "    elif bmi < 25:\n",
    "        return \"Normal\"\n",
    "    elif bmi < 30:\n",
    "        return \"Overweight\"\n",
    "    else:\n",
    "        return \"Obese\"\n",
    "\n",
    "df[\"BMI_Category\"] = df[\"BMI\"].apply(bmi_category)\n",
    "df[\"Glucose_BMI_Ratio\"] = df[\"Glucose\"] / df[\"BMI\"]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dac848",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45d5ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Outcome\"])\n",
    "y = df[\"Outcome\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1a348",
   "metadata": {},
   "source": [
    "## Pipelines with preprocessing + SMOTE + model\n",
    "We'll build reusable pipelines for Logistic Regression, Random Forest, and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35126b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"BMI_Category\"]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "numeric_prep = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_prep = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_prep, num_cols),\n",
    "    (\"cat\", categorical_prep, cat_cols)\n",
    "])\n",
    "\n",
    "def evaluate(name, y_true, y_pred, y_prob):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy :\", round(accuracy_score(y_true, y_pred), 4))\n",
    "    print(\"Precision:\", round(precision_score(y_true, y_pred), 4))\n",
    "    print(\"Recall   :\", round(recall_score(y_true, y_pred), 4))\n",
    "    print(\"F1-score :\", round(f1_score(y_true, y_pred), 4))\n",
    "    print(\"ROC-AUC  :\", round(roc_auc_score(y_true, y_prob), 4))\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\"); plt.show()\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_true, y_prob)\n",
    "    plt.title(f\"{name} - ROC Curve\"); plt.show()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "def make_lr_pipeline():\n",
    "    return ImbPipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"model\", LogisticRegression(max_iter=1000))\n",
    "    ])\n",
    "\n",
    "def make_rf_pipeline():\n",
    "    return ImbPipeline(steps=[\n",
    "        (\"prep\", preprocessor),\\\n",
    "        (\"smote\", SMOTE(random_state=42)),\\\n",
    "        (\"model\", RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "\n",
    "def make_xgb_pipeline():\n",
    "    return ImbPipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"model\", XGBClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.08,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc7ef84",
   "metadata": {},
   "source": [
    "## Train & evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = make_lr_pipeline().fit(X_train, y_train)\n",
    "y_pred_lr = lr_pipe.predict(X_test)\n",
    "y_prob_lr = lr_pipe.predict_proba(X_test)[:, 1]\n",
    "evaluate(\"Logistic Regression\", y_test, y_pred_lr, y_prob_lr)\n",
    "\n",
    "rf_pipe = make_rf_pipeline().fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipe.predict(X_test)\n",
    "y_prob_rf = rf_pipe.predict_proba(X_test)[:, 1]\n",
    "evaluate(\"Random Forest\", y_test, y_pred_rf, y_prob_rf)\n",
    "\n",
    "xgb_pipe = make_xgb_pipeline().fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipe.predict(X_test)\n",
    "y_prob_xgb = xgb_pipe.predict_proba(X_test)[:, 1]\n",
    "evaluate(\"XGBoost\", y_test, y_pred_xgb, y_prob_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61b8f2",
   "metadata": {},
   "source": [
    "## Cross-validation (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a246913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "auc_scores = cross_val_score(make_xgb_pipeline(), X, y, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "print(\"CV ROC-AUC (XGB):\", np.round(auc_scores, 4), \"Mean:\", round(auc_scores.mean(), 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897182c",
   "metadata": {},
   "source": [
    "## Explainability with SHAP (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a00eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the fitted XGB pipeline\n",
    "prep = xgb_pipe.named_steps[\"prep\"]\n",
    "model = xgb_pipe.named_steps[\"model\"]\n",
    "\n",
    "# Transform training data to model space\n",
    "X_train_proc = prep.transform(X_train)\n",
    "\n",
    "try:\n",
    "    num_features = preprocessor.named_transformers_[\"num\"].get_feature_names_out([*num_cols])\n",
    "except Exception:\n",
    "    num_features = np.array(num_cols)\n",
    "\n",
    "ohe = preprocessor.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
    "cat_features = ohe.get_feature_names_out([\"BMI_Category\"])  # aligned with ColumnTransformer\n",
    "feature_names = np.r_[num_features, cat_features]\n",
    "\n",
    "X_sample = X_train_proc if X_train_proc.shape[0] <= 200 else X_train_proc[:200]\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "shap.summary_plot(shap_values, X_sample, feature_names=feature_names, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b80533",
   "metadata": {},
   "source": [
    "## Save pipeline & predict on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(xgb_pipe, \"../diabetes_risk_pipeline.joblib\")\n",
    "print(\"Saved model -> ../diabetes_risk_pipeline.joblib\")\n",
    "\n",
    "new_patient = {\n",
    "    \"Pregnancies\": 2,\n",
    "    \"Glucose\": 145,\n",
    "    \"BloodPressure\": 80,\n",
    "    \"SkinThickness\": 25,\n",
    "    \"Insulin\": 100,\n",
    "    \"BMI\": 31.2,\n",
    "    \"DiabetesPedigreeFunction\": 0.35,\n",
    "    \"Age\": 45,\n",
    "    \"BMI_Category\": \"Obese\",\n",
    "    \"Glucose_BMI_Ratio\": 145/31.2\n",
    "}\n",
    "new_df = pd.DataFrame([new_patient])\n",
    "loaded = joblib.load(\"../diabetes_risk_pipeline.joblib\")\n",
    "prob = loaded.predict_proba(new_df)[:, 1][0]\n",
    "pred = loaded.predict(new_df)[0]\n",
    "print(f\"Probability of diabetes: {prob:.3f} -> Predicted class: {pred}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
